{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STuZ_x96mWXB",
        "outputId": "c11f0128-3ea7-4e47-e827-fdae8354d930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/134.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install groq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard imports\n",
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "# Setup Groq API key for test/demo\n",
        "os.environ['GROQ_API_KEY'] = \"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\"\n",
        "\n",
        "# Initialize Groq client\n",
        "client = Groq(api_key=os.environ['GROQ_API_KEY'])\n",
        "MODEL = \"llama-3.3-70b-versatile\"\n"
      ],
      "metadata": {
        "id": "-3KwdKWXuiUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions for truncation\n",
        "def truncate_by_turns(history, n):\n",
        "    return history[-n:]\n",
        "\n",
        "def truncate_by_chars(history, max_chars):\n",
        "    result = []\n",
        "    count = 0\n",
        "    for msg in reversed(history):\n",
        "        msg_len = len(msg['content'])\n",
        "        if count + msg_len > max_chars:\n",
        "            break\n",
        "        result.insert(0, msg)\n",
        "        count += msg_len\n",
        "    return result\n",
        "\n",
        "def truncate_by_words(history, max_words):\n",
        "    result, count = [], 0\n",
        "    for msg in reversed(history):\n",
        "        words = len(msg['content'].split())\n",
        "        if count + words > max_words:\n",
        "            break\n",
        "        result.insert(0, msg)\n",
        "        count += words\n",
        "    return result\n",
        "\n",
        "def summarize(history):\n",
        "    system_prompt = {\"role\": \"system\", \"content\": \"Summarize the conversation so far in 2 concise sentences.\"}\n",
        "    summary_msgs = [system_prompt] + history\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=summary_msgs\n",
        "    )\n",
        "    return resp.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "aVAQnFdavnds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A conversation runner with truncation and periodic summarization\n",
        "def conversation_demo(history, user_msg, k=3, trunc_type=\"turns\", limit=5, summarization_every=3):\n",
        "    # Add user message and assistant response\n",
        "    history.append({\"role\": \"user\", \"content\": user_msg})\n",
        "    assistant = client.chat.completions.create(model=MODEL, messages=history)\n",
        "    ai_msg = assistant.choices[0].message.content\n",
        "    history.append({\"role\": \"assistant\", \"content\": ai_msg})\n",
        "\n",
        "    # Truncate history\n",
        "    if trunc_type == \"turns\":\n",
        "        history = truncate_by_turns(history, limit)\n",
        "    elif trunc_type == \"chars\":\n",
        "        history = truncate_by_chars(history, limit)\n",
        "    elif trunc_type == \"words\":\n",
        "        history = truncate_by_words(history, limit)\n",
        "\n",
        "    # Summarize periodically\n",
        "    if len(history) // 2 % summarization_every == 0:\n",
        "        summary = summarize(history)\n",
        "        history = [{\"role\": \"system\", \"content\": f\"Summary: {summary}\"}]\n",
        "\n",
        "    return history\n",
        "\n",
        "# --- Demo Run ---\n",
        "# Initial empty conversation\n",
        "history = [{\"role\": \"system\", \"content\": \"You are a friendly AI assistant.\"}]\n",
        "sample_user_msgs = [\n",
        "    \"Hi there, can you tell me a fun fact?\",\n",
        "    \"What's the weather like in Paris?\",\n",
        "    \"Can you summarize our conversation?\",\n",
        "    \"Who won the last football world cup?\",\n",
        "    \"What is the capital of Japan?\"\n",
        "]\n",
        "# Demo, show conversation at each step with truncation and every-3rd-run summarization\n",
        "for i, msg in enumerate(sample_user_msgs):\n",
        "    history = conversation_demo(history, msg, k=3, trunc_type=\"turns\", limit=4, summarization_every=3)\n",
        "    print(f\"\\n--- After user message {i + 1} ---\\n\")\n",
        "    for h in history:\n",
        "        print(f\"{h['role'].capitalize()}: {h['content']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS9olpkNvpog",
        "outputId": "c81036e5-8a40-4963-b083-9f7ede526f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- After user message 1 ---\n",
            "\n",
            "System: You are a friendly AI assistant.\n",
            "User: Hi there, can you tell me a fun fact?\n",
            "Assistant: Here's a fun fact: Did you know that there is a species of jellyfish that is immortal? The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage and grow back into an adult again, making it theoretically immortal! Isn't that cool?\n",
            "\n",
            "--- After user message 2 ---\n",
            "\n",
            "User: Hi there, can you tell me a fun fact?\n",
            "Assistant: Here's a fun fact: Did you know that there is a species of jellyfish that is immortal? The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage and grow back into an adult again, making it theoretically immortal! Isn't that cool?\n",
            "User: What's the weather like in Paris?\n",
            "Assistant: Bonjour! The weather in Paris can vary depending on the time of year. Paris has a temperate climate, with four distinct seasons.\n",
            "\n",
            "Currently, I don't have real-time access to the current weather conditions in Paris. However, I can give you an idea of what the weather is typically like in Paris during different times of the year:\n",
            "\n",
            "* Spring (March to May): Mild temperatures, with average highs around 17°C (63°F) and lows around 8°C (46°F).\n",
            "* Summer (June to August): Warm and sunny, with average highs around 25°C (77°F) and lows around 15°C (59°F).\n",
            "* Autumn (September to November): Cooler temperatures, with average highs around 15°C (59°F) and lows around 8°C (46°F).\n",
            "* Winter (December to February): Cool and wet, with average highs around 8°C (46°F) and lows around 2°C (36°F).\n",
            "\n",
            "If you want to know the current weather conditions in Paris, I recommend checking a weather website or app, such as AccuWeather or the French national meteorological service, Météo-France, for the most up-to-date information.\n",
            "\n",
            "--- After user message 3 ---\n",
            "\n",
            "User: What's the weather like in Paris?\n",
            "Assistant: Bonjour! The weather in Paris can vary depending on the time of year. Paris has a temperate climate, with four distinct seasons.\n",
            "\n",
            "Currently, I don't have real-time access to the current weather conditions in Paris. However, I can give you an idea of what the weather is typically like in Paris during different times of the year:\n",
            "\n",
            "* Spring (March to May): Mild temperatures, with average highs around 17°C (63°F) and lows around 8°C (46°F).\n",
            "* Summer (June to August): Warm and sunny, with average highs around 25°C (77°F) and lows around 15°C (59°F).\n",
            "* Autumn (September to November): Cooler temperatures, with average highs around 15°C (59°F) and lows around 8°C (46°F).\n",
            "* Winter (December to February): Cool and wet, with average highs around 8°C (46°F) and lows around 2°C (36°F).\n",
            "\n",
            "If you want to know the current weather conditions in Paris, I recommend checking a weather website or app, such as AccuWeather or the French national meteorological service, Météo-France, for the most up-to-date information.\n",
            "User: Can you summarize our conversation?\n",
            "Assistant: We've had a chat about a few things so far. Here's a summary:\n",
            "\n",
            "1. I shared a fun fact with you about the Turritopsis dohrnii, also known as the \"immortal jellyfish\".\n",
            "2. You asked about the weather in Paris, and I provided some general information about the typical climate and temperatures in Paris during different times of the year.\n",
            "\n",
            "That's about it so far! Let me know if you'd like to continue the conversation or if you have any other questions.\n",
            "\n",
            "--- After user message 4 ---\n",
            "\n",
            "User: Can you summarize our conversation?\n",
            "Assistant: We've had a chat about a few things so far. Here's a summary:\n",
            "\n",
            "1. I shared a fun fact with you about the Turritopsis dohrnii, also known as the \"immortal jellyfish\".\n",
            "2. You asked about the weather in Paris, and I provided some general information about the typical climate and temperatures in Paris during different times of the year.\n",
            "\n",
            "That's about it so far! Let me know if you'd like to continue the conversation or if you have any other questions.\n",
            "User: Who won the last football world cup?\n",
            "Assistant: The last Football World Cup, also known as the FIFA World Cup, was held in 2018 in Russia. The winner of the tournament was France, who defeated Croatia 4-2 in the final on July 15, 2018, at the Luzhniki Stadium in Moscow.\n",
            "\n",
            "However, please note that there was also a World Cup held in 2022 in Qatar, which was won by Argentina, who defeated France 4-2 in a penalty shootout after the match ended 3-3 after extra time.\n",
            "\n",
            "Let me know if you have any other questions!\n",
            "\n",
            "--- After user message 5 ---\n",
            "\n",
            "User: Who won the last football world cup?\n",
            "Assistant: The last Football World Cup, also known as the FIFA World Cup, was held in 2018 in Russia. The winner of the tournament was France, who defeated Croatia 4-2 in the final on July 15, 2018, at the Luzhniki Stadium in Moscow.\n",
            "\n",
            "However, please note that there was also a World Cup held in 2022 in Qatar, which was won by Argentina, who defeated France 4-2 in a penalty shootout after the match ended 3-3 after extra time.\n",
            "\n",
            "Let me know if you have any other questions!\n",
            "User: What is the capital of Japan?\n",
            "Assistant: The capital of Japan is Tokyo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: JSON Schema Classification & Information Extraction**"
      ],
      "metadata": {
        "id": "sqLLMBtKxese"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo sample chats\n",
        "sample_chats = [\n",
        "    \"Hello, I'm Priya Shah from Mumbai. My email is priya@gmail.com and I'm 29 years old. Contact me on 9123456789.\",\n",
        "    \"My name is John, 34 years old, living in London. You can reach me at john_doe22@icloud.com or call 44011223344.\",\n",
        "    \"This is Maria, based in São Paulo, age 41. My number is +5511998877665, and my mail is maria.silva@email.com.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "aQsrmrFqynL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define JSON schema dictionary (no Function import)\n",
        "info_schema = {\n",
        "    \"name\": \"extract_user_info\",\n",
        "    \"description\": \"Extract user contact and demographic info from chat.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\":       {\"type\": \"string\", \"description\": \"User's name\"},\n",
        "            \"email\":      {\"type\": \"string\", \"description\": \"User's email\"},\n",
        "            \"phone\":      {\"type\": \"string\", \"description\": \"User's phone\"},\n",
        "            \"location\":   {\"type\": \"string\", \"description\": \"User's location\"},\n",
        "            \"age\":        {\"type\": \"integer\", \"description\": \"User's age\"}\n",
        "        },\n",
        "        \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Extraction and validation loop\n",
        "import json\n",
        "\n",
        "for chat in sample_chats:\n",
        "    chat_msgs = [\n",
        "        {\"role\": \"system\", \"content\": \"Extract user's name, email, phone, location, and age from their message.\"},\n",
        "        {\"role\": \"user\", \"content\": chat}\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=chat_msgs,\n",
        "        functions=[info_schema],\n",
        "        function_call={\"name\": \"extract_user_info\"}\n",
        "    )\n",
        "\n",
        "    # Extract and validate output\n",
        "    function_args = response.choices[0].message.function_call.arguments\n",
        "    try:\n",
        "        parsed = json.loads(function_args)\n",
        "        valid = all(parsed.get(field) for field in [\"name\", \"email\", \"phone\", \"location\", \"age\"])\n",
        "        print(f\"Chat: {chat}\\nExtracted: {parsed}\\nValid: {valid}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to parse/validate: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HWkJLh-xWea",
        "outputId": "8fdf070c-86c4-42de-93d3-f633c6cf1d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat: Hello, I'm Priya Shah from Mumbai. My email is priya@gmail.com and I'm 29 years old. Contact me on 9123456789.\n",
            "Extracted: {'age': 29, 'email': 'priya@gmail.com', 'location': 'Mumbai', 'name': 'Priya Shah', 'phone': '9123456789'}\n",
            "Valid: True\n",
            "\n",
            "Chat: My name is John, 34 years old, living in London. You can reach me at john_doe22@icloud.com or call 44011223344.\n",
            "Extracted: {'age': 34, 'email': 'john_doe22@icloud.com', 'location': 'London', 'name': 'John', 'phone': '44011223344'}\n",
            "Valid: True\n",
            "\n",
            "Chat: This is Maria, based in São Paulo, age 41. My number is +5511998877665, and my mail is maria.silva@email.com.\n",
            "Extracted: {'age': 41, 'email': 'maria.silva@email.com', 'location': 'São Paulo', 'name': 'Maria', 'phone': '+5511998877665'}\n",
            "Valid: True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Yarstick Groq Assignment\n",
        "# Conversation Management & Classification using Groq API\n",
        "# This file is a self-contained Google Colab-friendly Python script / notebook\n",
        "\n",
        "# -----------------------------\n",
        "# README.md (for GitHub)\n",
        "# -----------------------------\n",
        "\n",
        "readme_content = \"\"\"# Yarstick Groq API Assignment\n",
        "\n",
        "This repository contains my submission for the **Conversation Management & Classification** assignment using the **Groq API** with OpenAI-compatible SDK.\n",
        "\n",
        "## 📌 Tasks\n",
        "- **Task 1**: Manage conversation history, truncation, and periodic summarization.\n",
        "- **Task 2**: JSON schema classification & information extraction with function-calling.\n",
        "\n",
        "## 🚀 How to Run\n",
        "1. Open the notebook in **Google Colab** or Jupyter Notebook.\n",
        "2. Install requirements:\n",
        "   ```bash\n",
        "   pip install -r requirements.txt\n",
        "   ```\n",
        "3. Set your **Groq API key**:\n",
        "   ```python\n",
        "   import os\n",
        "   os.environ[\"GROQ_API_KEY\"] = \"<your-api-key>\"\n",
        "   ```\n",
        "4. Run all cells to reproduce results.\n",
        "\n",
        "## 📂 Repository Structure\n",
        "```\n",
        "yarstick-groq-assignment/\n",
        "│── yarstick_groq_assignment.ipynb   # Main notebook\n",
        "│── requirements.txt                 # Python dependencies\n",
        "│── README.md                        # This file\n",
        "```\n",
        "\n",
        "## 🔑 Notes\n",
        "- API key is **not included** in this repo. Set it manually in Colab or your local environment.\n",
        "- The notebook demonstrates:\n",
        "  - Conversation management with summarization every k turns.\n",
        "  - Truncation by turns and by character length.\n",
        "  - JSON schema-based structured extraction of user details.\n",
        "- Outputs are shown in the notebook for evaluation.\n",
        "\"\"\"\n",
        "\n",
        "with open(\"README.md\", \"w\") as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "# -----------------------------\n",
        "# requirements.txt (for GitHub)\n",
        "# -----------------------------\n",
        "\n",
        "requirements_content = \"\"\"openai\n",
        "requests\n",
        "jsonschema\n",
        "\"\"\"\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as f:\n",
        "    f.write(requirements_content)\n",
        "\n",
        "print(\"README.md and requirements.txt have been generated. Upload them to GitHub along with your notebook.\")\n"
      ],
      "metadata": {
        "id": "-UuYk24S4n5C",
        "outputId": "6d33d6c9-c466-4c48-8e82-505566077c91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md and requirements.txt have been generated. Upload them to GitHub along with your notebook.\n"
          ]
        }
      ]
    }
  ]
}